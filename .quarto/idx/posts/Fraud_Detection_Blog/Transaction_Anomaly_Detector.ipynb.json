{"title":"Practical Approach for idenitfying Transactional Anomalies","markdown":{"headingText":"Practical Approach for idenitfying Transactional Anomalies","containsRefs":false,"markdown":"\n\n**Motivation:**\n\nIn this guide, you'll learn how to get started with Anomaly Detection using Python, including:\n\n\n1.   What is Anamoly?\n2.   What are the challenges of Traditional methods to do Anamoly?\n3.   Using Isolation Forest for Anamoly Detection.\n4.   How to explain the results?\n\n\n\n**Problem and Requirements:**\n\nIn finance Such as Banking , Ecommerce some users perform illegal transactions in the database and those transactions leave records in database. How ever this database is mostly composed of non criminal transactions from the people who comply with the rules of the system they are part of.\n\n**Goal:** To identify this Fraudulant Transactions by means of running our Database through Anamoly detection system.\n\n**Good news:** Our database has all the records for idenitfy the crime.No need for data gathering.\n\n**Bad news:** Fraudlent transactions of the data is buried in millions of records and you might not recognise fradualnt transaction in the records.\n\n**Challenges:**\n\nNeed for automation mainly because the sheer size of the records make the manual validation of the data to identify the anomaly is impossible to check all records.\n\nIf the problem is that the human expersts dont have the time to go through the dataset can we try to automate their decision process?\n\n**Rule Based approach** - \nIf experts could complie a set of rules for instance transactions that exceed a certain amount are anomaly or transactions of certain type X at certain time Y are considered anolmaly etc. Any type of clearly defined rule to singleout a fradualant transaction. With this rule we can easily implement a system that\ncan easily flag any anamolous transaction.that fullfill the rules of anamoly.\n \n\n*   How ever they are several problems with this approach. \nComing up with a good set of rules require a lot of expertise and work rule needs to be validated and for particular dataset at hand.\n*   If the dataset format changes or a different dataset is used with different distribution the complete set of rules\nneed to be reworked to reflect the new situation.\n\n\nFinally and most importantly its impossible to predict to all shapes and forms that anomalies can assume.\n\n**Solution to the above challenge:** To address this problem of unknown nature of fraudulent transactions we can make use of data we have in the database.\nWe have to build a system which learns from the data what constitues an anomly.\n\nWe have to put the requirement that the model has to be unsupervised\nmeaning that when we train this model we will not be able to tell that\nwhich are anamoly or not. we dont have any information on that so far.\n\n**Machine Learning approach:**\nfirst step we train a unsupervised model on our data to learn about \n\n1.   First step we train a unsupervised model on our data to learn about distribution of data and to get a sense of what an anamoly is in our context.\n2.   In step two we use this model to predict the likelihood of a transaction being fraud for every transaction using what it has learned in the above step.\n\nA machine learning model will never give a definitive answer of whether a transaction is anamoly\ntheir will be always an inheriant uncertanity in the answers it give us. If our model gives a continous value as anamoly score that refelcts the model certanity\nof the transaction likely to be anamoly we can choose ourself how wide we want to cast our net while looking for possible anamoly.\n\nThe output of the model will be a mapping of every transaction to certain a anamoly score. This score reflects how certain our model is of certain transaction as anamoly or not. If we want to consider some subset of transaction we have to set a threshold. the nature of anamoly \nwill help us to consider how wider net we want to perform . Downside is we might not undestand why a transaction is anamoly .thats why we have explanability to the model to understand why model has flagged a certain transaction as anamoly.\n\n**Dataset:**\n\n**About Data:**\nstep - maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).\ntype - CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER.\n\namount - amount of the transaction in local currency.\n\nnameOrig - customer who started the transaction\n\noldbalanceOrg - initial balance before the transaction\n\nnewbalanceOrig - new balance after the transaction\n\nnameDest - customer who is the recipient of the transaction\n\noldbalanceDest - initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants).\n\nnewbalanceDest - new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants).\n\nisFraud - This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system.\n\nisFlaggedFraud - The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction.\n\n\n\n**Feature Engineering:**\n\n**Isolation Forest:**\n\n**Model:**\n\n**Top Outliers:**\n\n**Results:**\n\n**Explanability:**\n\nExplanation for local points\n\nThe above plot shows how the individual features of the data point contributed to shifting the model output from its expected to base value. These contributing values are called SHAP values. Blue values are contributing to lower the anamoly score and the red values for higher anamoly score.\n\nFor the above entry features such as amount(higher amount) is suggestive that the data is anamolous.\n\nSHAP values are local explanations of different features for a given data point. To gain the global trends by aggregating the local explanations.\n\nSHAP library has a library called dependence plot which shows us how mulitple datapoints of shap value depend on the feature .\n\n**Conclusion:**\n\n\nThe above guide demonstrates how to get started with Anomaly Detection using Python and the Isolation Forest algorithm. The guide explains the challenges of traditional methods for anomaly detection, such as rule-based approaches, and provides a solution to these challenges by using a machine learning approach. The guide uses the Isolation Forest algorithm to train a model on the data and predict the likelihood of a transaction being fraudulent based on the learned information. The guide also explains how to evaluate the results and provides code for visualizing the results using SHAP. The conclusion of the guide is that using a machine learning approach, specifically the Isolation Forest algorithm, can effectively identify fraudulent transactions in large datasets and provide a certain level of certainty in its predictions.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"toc-depth":3,"output-file":"Transaction_Anomaly_Detector.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","theme":"cosmo","title-block-banner":false,"author":"Lakshmi Putta","page-layout":"article"},"extensions":{"book":{"multiFile":true}}}}}